# 併發相關 各類鎖的比較

今天來比較一下C++中各類鎖的特性，目標是能清楚在什麼場景下哪些鎖能派上用場，以及為什麼要用他

## 鎖的類型

C++中有 `mutex`, `recursive_mutex`, `timed_mutex`, `shared_mutex` (C++17才支援) 這幾種互斥鎖類型。

不過實務場景(我自己的經驗)主要會是以 互斥鎖(`mutex`), 讀寫鎖(`shared_mutex`), 自旋鎖(`spin_lock`) 這三種為主

### 自旋鎖 spin_lock

這邊簡單介紹一下自旋鎖，一般的互斥鎖在上鎖後，其他線程要取用的時候，是會進入一個阻塞狀態，但如果是自旋鎖的話，會進去忙等待(busy-wait)，也就是不斷去確認鎖是否被釋放。

- 優點
  - 低延遲: 能夠減少線程上下文切換，因為忙等待是在使用者層，就不是在kernel層
- 缺點
  - 耗能高: 因為一直忙等待會導致等待線程過度使用CPU
  - 不適合長時間持有: 同上面一點，過多等待性能會下降明顯，同時在高度競爭下也同樣

## 使用場景

會使用到鎖的場景，主要是因為在多線程的場景，程序中的共享資源會被不同區塊使用，為了要確保這些資源的一致性，而需要鎖來保障一致性。

換句話說，使用到鎖的場景，本身就一定程度上確保了 `強一致性`，而對資源的使用，無外乎就是 `讀` 與 `寫` ，所以這邊就來看看基於讀寫比率不同的場景下，該使用哪些鎖 (下面表格是由 AI 生成)

| 讀 / 寫 比例   | 實務場景                                             | 推薦鎖型                                                                | 備註                                                                                           |
| -------------- | ---------------------------------------------------- | ----------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **讀多／寫少** | 行情快照、風控規則查詢、靜態設定表（config）         | `std::shared_mutex`（讀用 `std::shared_lock`，寫用 `std::unique_lock`） | 多讀少寫時最划算；但若寫入偶爾突發、讀臨界區偏長，寫者可能飢餓。極端讀多場景可考慮快照或 RCU。 |
| **讀多／寫多** | 倉位資料、使用者資金表、持倉快照（頻繁更新又頻繁查） | `std::mutex` + **分段鎖（shard per key）** 或 **細粒度鎖**              | 單一共享鎖效能差，應拆分鎖粒度；或以 lock-free 結構、atomic snapshot 改寫。                    |
| **讀少／寫少** | 系統設定值、任務隊列、偶爾更新的共享物件             | `std::mutex`                                                            | 最簡單、穩定；爭用不高時開銷最小。                                                             |
| **讀少／寫多** | 撮合引擎、風控計算累計器、高頻資料寫入               | `std::mutex` 或 **Hybrid 自旋鎖（spin + mutex fallback）**              | 寫多時 `shared_mutex` 反而慢；臨界區極短時可用自旋鎖。                                         |

## 驗證場景

以一個類似行情物件為基礎，我會定義一個容器類別來管理行情物件，同時定義一個Reader類別，來向容器讀取這些物件，並另外再定義一個Writer類別來不斷向容器寫入行情。

基於上述場景的定義，我就能藉由擴增Reader及Writer的數量，來模擬不同的讀/寫比例的場景了。

場景提到的實作能從我的[Mutex Cpp](https://github.com/steven715/mutex_cpp)看到，下面就直接展示相關結果。

## 測試結果

### 場景1：低寫入高讀取 (1W:10R)

| 鎖類型     | 讀取次數 | 寫入次數 | 平均讀取時間 | 平均寫入時間 | 讀寫比例     |
| ---------- | -------- | -------- | ------------ | ------------ | ------------ |
| 一般互斥鎖 | 551,754  | 55,274   | 1.23 μs      | 2.61 μs      | 90.9% / 9.1% |
| 讀寫鎖     | 546,374  | 54,564   | 1.42 μs      | 3.43 μs      | 90.9% / 9.1% |
| 自旋鎖     | 555,394  | 55,427   | **0.56 μs**  | **2.40 μs**  | 90.9% / 9.1% |


---

### 場景2：平衡讀寫 (1W:1R)

| 鎖類型     | 讀取次數 | 寫入次數 | 平均讀取時間 | 平均寫入時間 | 讀寫比例      |
| ---------- | -------- | -------- | ------------ | ------------ | ------------- |
| 一般互斥鎖 | 54,261   | 54,235   | 1.91 μs      | 4.15 μs      | 50.0% / 50.0% |
| 讀寫鎖     | 53,179   | 53,072   | 2.06 μs      | 4.43 μs      | 50.1% / 49.9% |
| 自旋鎖     | 53,521   | 53,450   | **1.24 μs**  | **3.95 μs**  | 50.0% / 50.0% |


---

### 場景3：高寫入低讀取 (10W:1R)

| 鎖類型     | 讀取次數 | 寫入次數 | 平均讀取時間 | 平均寫入時間 | 讀寫比例     |
| ---------- | -------- | -------- | ------------ | ------------ | ------------ |
| 一般互斥鎖 | 55,662   | 556,424  | 1.91 μs      | 3.71 μs      | 9.1% / 90.9% |
| 讀寫鎖     | 54,549   | 546,160  | 2.37 μs      | 4.19 μs      | 9.1% / 90.9% |
| 自旋鎖     | 55,518   | 554,919  | **0.91 μs**  | **2.78 μs**  | 9.1% / 90.9% |


---

### 場景4：極高競爭 (10W:10R)

| 鎖類型     | 讀取次數 | 寫入次數 | 平均讀取時間 | 平均寫入時間 | 讀寫比例      |
| ---------- | -------- | -------- | ------------ | ------------ | ------------- |
| 一般互斥鎖 | 558,735  | 558,465  | 1.71 μs      | 3.07 μs      | 50.0% / 50.0% |
| 讀寫鎖     | 551,027  | 549,873  | 1.97 μs      | 4.43 μs      | 50.1% / 49.9% |
| 自旋鎖     | 551,776  | 551,281  | **0.83 μs**  | **2.28 μs**  | 50.0% / 50.0% |

## 總體性能分析

### 平均讀取時間比較（所有場景平均）
1. **自旋鎖**: 0.89 μs ⭐
2. **一般互斥鎖**: 1.69 μs
3. **讀寫鎖**: 1.96 μs

### 平均寫入時間比較（所有場景平均）
1. **自旋鎖**: 2.85 μs ⭐
2. **一般互斥鎖**: 3.39 μs
3. **讀寫鎖**: 4.12 μs

## 結論

基本上看到的結果是**自旋鎖**表現最佳，而**互斥鎖**則是非常平穩，但也有可能跟這次的測試環境與場景只是單純的讀取、寫入有關，讓純CPU多工的場景能有效發揮，因為其中沒有涉及鎖的時間若變長的場景，所以結論也算是符合預期，以及未來有機會也會在以這個[Mutex Cpp](https://github.com/steven715/mutex_cpp)上繼續延伸跟探討更多相關的多執行緒效能場景!
